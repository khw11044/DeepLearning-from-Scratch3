{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Step47, 소프트맥스 함수와 교차 엔트로피 오차 \n",
    "\n",
    "지금까지 신경망을 사용하여 회귀문제를 풀었다.\n",
    "\n",
    "다중 클래스 분류(multi-class classification) : '여러 클래스'로 '분류'하는 문제  \n",
    "분류 대상이 여러 가지 클래스 중 어디에 속하는지 추정\n",
    "\n",
    "다중 클래스 분류를 구현해 본다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 47 부록, get_item 함수 구현\n",
    "\n",
    "Variable의 다차원 배열 중에서 일부를 슬라이스 하여야하는데 이때 사용한는 것이 get_item이다.  \n",
    "\n",
    "먼저 get_item 함수를 구현해본다"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dezero/functions.py\n",
    "from dezero import Function\n",
    "\n",
    "class GetItem(Function):\n",
    "    def __init__(self, slices):\n",
    "        self.slices = slices        # 슬라이스 연산을 수행하는 인수 slices를 받아 인스턴스 변수에 저장\n",
    "    \n",
    "    def forward(self, x):           \n",
    "        y = x[self.slices]          # 단순히 slices 변수를 이용해 원소를 추출하고 있다\n",
    "        return y \n",
    "    \n",
    "    def backward(self, gy):         # 슬라이스 조작에 대응하는 역전파 계산이 DeZero 함수중에 없으므로\n",
    "        x, = self.inputs\n",
    "        f = GetItemGrad(self.slices, x.shape)   # 새로 클래스를 만들어 사용해야 한다\n",
    "        return f(gy)\n",
    "\n",
    "def get_item(x, slices):\n",
    "    return GetItem(slices)(x)"
   ]
  },
  {
   "source": [
    "초기화 시 슬라이스 연산을 수행하는 인수 slices를 받아 인스턴스 변수에 저장하고  \n",
    "forward(x) 메서드에서는 단순히 이 변수를 이용해 원소를 추출하고 있다.  \n",
    "그런데 슬라이스 조작에 대응하는 역전파 계산은 DeZero 함수 중에는 없다.  \n",
    "그래서 별도로 GetItemGrad라는 새로운 DeZero 함수 클래스를 제공한다.\n",
    "\n",
    "즉, GetItemGrad의 순전파가 GetItem의 역전파에 대응하도록 구현하였다.\n",
    "\n",
    "GetItemGrad 클래스 코드를 살펴보자."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# dezero/functions.py\n",
    "class GetItemGrad(Function):\n",
    "    def __init__(self, slices, in_shape): # 초기화 메서드에서 슬라이스 연산 인수(slices)와 입력 데이터의 모양(in_shape)\n",
    "        self.slices = slices\n",
    "        self.in_shape = in_shape\n",
    "\n",
    "    def forward(self, gy):      \n",
    "        gx = np.zeros(self.in_shape)    # 입력용 기울기로서 원소가 모두 0인 다차원 배열 gx를 준비\n",
    "        np.add.at(gx, self.slices, gy)  # gx의 원소 중 self.slices로 지정한 위치에 gy가 더해진다\n",
    "        return gx \n",
    "    \n",
    "    def backward(self, ggx):\n",
    "        return get_item(ggx, self.slices)"
   ]
  },
  {
   "source": [
    "초기화 메서드에서 슬라이스 연산 인수(slices)와 함께 입력 데이터의 모양(in_shape)을 받는다.  \n",
    "그리고 주 계산(forward)에서는 입력용 기울기로서 원소가 모두 0인 다차원 배열 gx를 준비한 다음  \n",
    "np.add.at(gx,self.slices,gy)를 실행  \n",
    "그 결과 gx의 원소 중 self.slices로 지정한 위치에 gy가 더해진다.\n",
    "\n",
    "np.add.at 함수 사용법을 살펴본다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0.]\n [0. 0. 0.]]\n[1. 1. 1.]\n[[0. 0. 0.]\n [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "a = np.zeros((2,3))\n",
    "print(a)\n",
    "\n",
    "b = np.ones((3,))\n",
    "print(b)\n",
    "\n",
    "slices = 1\n",
    "np.add.at(a,slices,b)\n",
    "print(a)"
   ]
  },
  {
   "source": [
    "다음으로 np.add.at 함수에 대응하는 역전파를 구현해야한다.  \n",
    "그런데 get_item함수가 그 일을 해준다.\n",
    "\n",
    "GetItem의 backward는 GetItemGrad \n",
    "GetItemGrad의 backward는 GetItem"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 47.1 슬라이스 조작 함수 \n",
    "\n",
    "다시 돌아와서 get_item 함수가 준비되었고 get_item 함수 사용 예를 보자"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([4 5 6])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from dezero import Variable\n",
    "import dezero.functions as F \n",
    "\n",
    "x = Variable(np.array([[1,2,3],[4,5,6]]))\n",
    "y = F.get_item(x,1) # (2,3) shape의 x에서 1번째 행의 원소를 추출\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "이와 같이 get_item 함수는 Variable의 다차원 배열 중에서 일부를 슬라이스하여 뽑아준다"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([[0. 0. 0.]\n          [1. 1. 1.]])\n"
     ]
    }
   ],
   "source": [
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "source": [
    "슬라이스로 인한 '계산'은 다차원 배열의 데이터 일부를 수정하지 않고 전달하는 것  \n",
    "따라서  \n",
    "그 역전파는 원래의 다차원 배열에서 데이터가 추출된 위치에 해당 기울기를 설정, 그 외에는 0으로 설정(그대로 옮기기만 한거니깐)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "또한 get_item 함수를 사용하면 인덱스를 반복 지정하여 동일한 원소를 여러번 때낼 수 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([[1 2 3]\n          [1 2 3]\n          [4 5 6]])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(np.array([[1,2,3],[4,5,6]]))\n",
    "indices = np.array([0,0,1])\n",
    "y = F.get_item(x, indices)\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "get_item 함수를 Variable의 메서드로도 사용할 수 있게 특수 메서드로 설정 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([4 5 6])\nvariable([3 6])\n"
     ]
    }
   ],
   "source": [
    "Variable.__getitem__ = F.get_item   # Variable의 메서드로 설정 \n",
    "\n",
    "y = x[1]\n",
    "print(y)\n",
    "\n",
    "y = x[:,2]\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "이렇게 하면 x\\[1\\]이나 x\\[:,2\\]등의 기법을 사용할 때도 get_item 함수가 불린다.  \n",
    "게다가 이 슬라이스 작업의 역전파도 올바르게 이루어진다.\n",
    "\n",
    "이 특수 메서드 설정은 dezero/core.py의 setup_variable 함수에 넣는다.\n",
    "\n",
    "~~~python\n",
    "def setup_variable():\n",
    "    Variable.__getitem__ = dezero.functions.get_item\n",
    "~~~\n",
    "\n",
    "이것으로 Variable 인스턴스를 자유롭게 슬라이스 할 수 있게 되었다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 47.2 소프트맥스 함수 \n",
    "\n",
    "다중 클래스 분류를 신경망으로 하게 되면  \n",
    "선형회귀때 이용한 신경망을 그대로 사용할 수 있다.  \n",
    "--> 앞서 MLP 클래스로 구현해둔 신경망을 그대로 이용할 수 있다는 뜻"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([[ 0.82225048  0.09579651 -0.32184872]])\n"
     ]
    }
   ],
   "source": [
    "from dezero.models import MLP \n",
    "\n",
    "model = MLP((10,3))\n",
    "\n",
    "x = np.array([[0.2, -0.4]])\n",
    "y = model(x)\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "x의 shape이 (1,2)인 샘플 데이터 하나 --> 원소가 2개인 2차원 벡터   \n",
    "신경망의 출력 형태 (1,3), 3차원 벡터의 원소 각각이 하나의 클래스에 해당   \n",
    "\n",
    "출력된 벡터에서 값이 가장 큰 원소의 인덱스가 이 모델이 분류한(정답이라고 예측한) 클래스이다.  \n",
    "2번 원소의 값이 가장 크기 때문에 2번 클래스로 분류 \n",
    "\n",
    "하지만 신경망의 출력이 단순히 '수치'이며 이 수치를 '확률'로 변환해줘야 한다.  \n",
    "이것을 해주는 것이 소프트맥스 함수(softmax function)\n",
    "\n",
    "$$p_k = \\frac{exp(y_k)}{\\sum_{i=1}^{n} exp(y_i)} \\qquad \\qquad \\qquad \\qquad  \\qquad (1)$$\n",
    "\n",
    "소프트맥스 함수의 입력 $y_k$ 총 n개라고 가정(n : '클래스 수')\n",
    "\n",
    "(1)은 k번째 출력 $p_k$를 구하는 계산식을 나타냄"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "입력 데이터가 하나인 경우의 소프트맥스 함수 구현"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dezero import Variable, as_variable\n",
    "import dezero.functions as F \n",
    "\n",
    "def softmax1d(x):\n",
    "    x = as_variable(x)  # x가 ndarray 인스턴스인 경우 Variable 인스턴스로 변환\n",
    "    y = F.exp(x)\n",
    "    sum_y = F.sum(y)\n",
    "    return y / sum_y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([[ 0.82225048  0.09579651 -0.32184872]])\nvariable([[0.55489844 0.26836047 0.17674109]])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(np.array([[0.2,-0.4]]))\n",
    "y = model(x)\n",
    "p = softmax1d(y)\n",
    "\n",
    "print(y)\n",
    "print(p)    # '확률'로 변환"
   ]
  },
  {
   "source": [
    "배치 데이터에 소프트맥스 함수를 적용할 수 있도록 확장"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dezero/functions.py \n",
    "\n",
    "def softmax_simple(x, axis=1):\n",
    "    x = as_variable(x)\n",
    "    y = exp(x)\n",
    "    sum_y = sum(y, axis=axis, keepdims=True)\n",
    "    return y / sum_y"
   ]
  },
  {
   "source": [
    "위 코드들은 간단한 구현  \n",
    "가장 좋은 방법은 Function 클래스를 상속하여 Softmax 클래스를 구현하고 파이썬 함수로 Softmax를 구현"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions.py\n",
    "from dezero import Function\n",
    "\n",
    "class Softmax(Function):\n",
    "    def __init__(self, axis=1):\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x - x.max(axis=self.axis, keepdims=True)\n",
    "        y = np.exp(y)\n",
    "        y /= y.sum(axis=self.axis, keepdims=True)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        y = self.outputs[0]()\n",
    "        gx = y * gy\n",
    "        sumdx = gx.sum(axis=self.axis, keepdims=True)\n",
    "        gx -= y * sumdx\n",
    "        return gx\n",
    "\n",
    "\n",
    "def softmax(x, axis=1):\n",
    "    return Softmax(axis)(x)"
   ]
  },
  {
   "source": [
    "## 47.3 교차 엔트로피 오차 \n",
    "\n",
    "선형 회귀에서는 손실 함수로 mean_squared_error(평균제곱오차)이용  \n",
    "다중 클래스 분류에 적합한 손실 함수 : 교차 엔트로피 오차(cross entropy error)\n",
    "\n",
    "$$L = - \\sum_k t_k \\log p_k$$\n",
    "\n",
    "$t_k$ : 정답 데이터의 k차원째 값을 나타냄  \n",
    "정답 데이터의 각 원소는 정답에 해당하는 클래스면 1, 그렇지 않으면 0으로 기록 : one-hot vector 방식 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "$t = (0,0,1)$이고 $p = (p_0,p_1,p_2)$ 인 경우를 대입하면 $L = -\\log p_2$ 이다.  \n",
    "즉 정답 클래스에 해당하는 번호의 확률 p를 추출함으로써 cross entropy error를 계산할 수 있다.  \n",
    "따라서 정답 데이터에 의해 정답 클래스의 번호가 t로 주어지면 아래와 같이 표현할 수 있다.\n",
    "\n",
    "$$L = -\\log p[t]$$\n",
    "(p\\[t\\]는 p에서 t번째 요소만 추출한다는 뜻)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**CAUTION_** 만약 데이터가 N개라면 각 데이터에서 cross entropy error를 구하고, 전체를 더한 다음 N으로 나눈다.  \n",
    "즉, mean cross entropy error를 구한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "'softmax funtion'과 'cross entropy error'를 한꺼번에 수행하는 함수를 구현 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dezero/functions.py \n",
    "\n",
    "def sofmax_cross_entropy_simple(x, t):\n",
    "    x, t = as_variable(x), as_variable(t)\n",
    "    N = x.shape[0]\n",
    "\n",
    "    p = softmax(x)  # 또는 softmax_simple(x)\n",
    "    p = clip(p, 1e-15, 1.0) # log(0)을 방지하기 위해 p의 값을 1e-15 이상으로 한다. \n",
    "    log_p = log(p)  # log는 DeZero 함수 \n",
    "    tlog_p = log_p[np.arange(N), t.data]\n",
    "    y = -1 * sum(tlog_p) / N\n",
    "    return y\n"
   ]
  },
  {
   "source": [
    "인수 x: 신경망에서 소프트맥스 함수를 적용하기 전의 출력  \n",
    "인수 t: 정답 데이터, 정답 클래스의 번호(레이블)가 주어진다고 가정  \n",
    "\n",
    "p = softmax(x)에서 p의 원소값은 0이상 1이하 (0을 log에 건내면 오류가 발생 clip함수 사용)\n",
    "log 계산 수행\n",
    "np.arange(N): \\[0,1,...,N-1\\] 형태의 ndarray 인스턴스를 생성  \n",
    "log_p\\[np.arange(N), t.data\\] 코드는 log_p\\[0, t.data\\[0\\]\\], log_p\\[1, t.data\\[1\\]\\], ..... 와 정답 데이터 (t.data)에 대응하는 모델을 출력을 구하고 그 값을 1차원 배열에 담아줌"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable(1.085969860341805)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0.2,-0.4], [0.3,0.5], [1.3,-3.2], [2.1, 0.3]])\n",
    "t = np.array([2, 0, 1, 0])\n",
    "y = model(x)\n",
    "loss = F.softmax_cross_entropy_simple(y,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clip(Function):\n",
    "    def __init__(self, x_min, x_max):\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = np.clip(x, self.x_min, self.x_max)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x, = self.inputs\n",
    "        mask = (x.data >= self.x_min) * (x.data <= self.x_max)\n",
    "        gx = gy * mask\n",
    "        return gx\n",
    "\n",
    "\n",
    "def clip(x, x_min, x_max):\n",
    "    return Clip(x_min, x_max)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log(Function):\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x)\n",
    "        y = xp.log(x)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x, = self.inputs\n",
    "        gx = gy / x\n",
    "        return gx\n",
    "\n",
    "\n",
    "def log(x):\n",
    "    return Log()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}